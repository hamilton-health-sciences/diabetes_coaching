{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tableone import TableOne\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import ParameterGrid, cross_validate\n",
    "\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "from pydtr.iqlearn.regression import IqLearnReg\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.2\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient Characteristics (State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import baseline and followup data\n",
    "data = pd.read_csv('data/baseline_followup.csv')\n",
    "data['VISIT DATE'] = pd.to_datetime(data['VISIT DATE'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical variables\n",
    "covariate_num = [\n",
    "    'BMI',\n",
    "    'Duration of diabetes',\n",
    "    'HbA1c',\n",
    "    'Age',\n",
    "    'Family physican visits',\n",
    "    'Family physican visits related to diabetes',\n",
    "    'EQ5D',\n",
    "    'AddQoL',\n",
    "    'DSCA_general diet',\n",
    "    'DSCA_specific diet',\n",
    "    'DSCA_exercise',\n",
    "    'DSCA_glucose',\n",
    "    'DSCA_footcare',\n",
    "    'DSCA_smoking2',\n",
    "    'DSCA_additional diet',\n",
    "    'DSCA_additional medication',\n",
    "    'DSCA_additional footcare'\n",
    "]\n",
    "\n",
    "# Categorical variables\n",
    "covariate_cat = [\n",
    "    'Gender',\n",
    "    'Ethnicity',\n",
    "    'Diabetes treatment (diet)',\n",
    "    'Diabetes treatment (oral therapy)',\n",
    "    'Diabetes treatment (Insulin)',\n",
    "    'Diabetes treatment (Other)',\n",
    "    'Stroke',\n",
    "    'Transient Ischemc Attack',\n",
    "    'Evidence of CAD',\n",
    "    'Myocardial infarction',\n",
    "    'Heart Failure',\n",
    "    'Kidney Disease',\n",
    "    'COPD',\n",
    "    'Hyperlipidemia',\n",
    "    'Hypertension',\n",
    "    'Peripheral Arterial Disease',\n",
    "    'Previous limb amputation',\n",
    "    'Prescribed medications', \n",
    "    'Behavioral stage',\n",
    "    'Chronic disease mgmt program',\n",
    "    'Visits with health professional',\n",
    "    'ER/hospital admissions',\n",
    "    'DSCA_smoking1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess patient characteristics and generate Table 1\n",
    "table1 = TableOne(data, columns = covariate_num+covariate_cat+['VISIT'], categorical = covariate_cat, groupby = 'VISIT', pval = True)\n",
    "table1.to_csv('table1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome (Reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative HbA1c reduction and EQ5D improvement\n",
    "for i in set(data['id']):\n",
    "    # HbA1c\n",
    "    data.loc[(data['id']==i)&(data['VISIT']==1), 'HbA1c_reduction_rel'] = (data[(data['id']==i)&(data['VISIT']==0)]['HbA1c'].values-data[(data['id']==i)&(data['VISIT']==1)]['HbA1c'].values)/data[(data['id']==i)&(data['VISIT']==0)]['HbA1c'].values\n",
    "    data.loc[(data['id']==i)&(data['VISIT']==2), 'HbA1c_reduction_rel'] = (data[(data['id']==i)&(data['VISIT']==0)]['HbA1c'].values-data[(data['id']==i)&(data['VISIT']==2)]['HbA1c'].values)/data[(data['id']==i)&(data['VISIT']==0)]['HbA1c'].values\n",
    "    # EQ5D\n",
    "    data.loc[(data['id']==i)&(data['VISIT']==1), 'EQ5D_improve_rel'] = (data[(data['id']==i)&(data['VISIT']==1)]['EQ5D'].values-data[(data['id']==i)&(data['VISIT']==0)]['EQ5D'].values)/data[(data['id']==i)&(data['VISIT']==0)]['EQ5D'].values\n",
    "    data.loc[(data['id']==i)&(data['VISIT']==2), 'EQ5D_improve_rel'] = (data[(data['id']==i)&(data['VISIT']==2)]['EQ5D'].values-data[(data['id']==i)&(data['VISIT']==0)]['EQ5D'].values)/data[(data['id']==i)&(data['VISIT']==0)]['EQ5D'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive the composite clinical outcome as relative HbA1c reduction and relative EQ5D improvement (normalized to [0,1], with a higher score being better)\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "data.loc[data['VISIT'].isin({1,2}), 'HbA1c_rel_scaled'] = scaler.fit_transform(data.loc[data['VISIT'].isin({1,2}), 'HbA1c_reduction_rel'].values.reshape(-1,1))\n",
    "data.loc[data['VISIT'].isin({1,2}), 'EQ5D_rel_scaled'] = scaler.fit_transform(data.loc[data['VISIT'].isin({1,2}), 'EQ5D_improve_rel'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['VISIT']==1][['id', 'HbA1c_reduction_rel', 'EQ5D_improve_rel', 'HbA1c_rel_scaled', 'EQ5D_rel_scaled']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['VISIT']==2][['id', 'HbA1c_reduction_rel', 'EQ5D_improve_rel', 'HbA1c_rel_scaled', 'EQ5D_rel_scaled']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coaching (Action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import coaching data\n",
    "data_coaching = pd.read_csv('data/coaching.csv')\n",
    "data_coaching['date of coaching'] = pd.to_datetime(data_coaching['date of coaching'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group coaching recommendations into three big groups of treatments\n",
    "## treatment BC+DE (behavior change and diabetes education): Dietary modification, Exercise modification, Behavioural modification\n",
    "## treatment CM (case management): Medication adherence, Medication adjustment, Glucose monitoring, Case-management/monitoring, System navigation\n",
    "## treament PS (psychosocial support): Psychosocial support and/or counselling\n",
    "data_coaching['treatment_BC+DE'] = data_coaching[[\n",
    "        'Dietary modification', \n",
    "        'Exercise modification', \n",
    "        'Behavioural modification']].sum(axis = 1)\n",
    "data_coaching['treatment_CM'] = data_coaching[[\n",
    "        'Medication adherence', \n",
    "        'Medication adjustment', \n",
    "        'Glucose monitoring', \n",
    "        'Case-management/monitoring', \n",
    "        'System navigation']].sum(axis = 1)\n",
    "data_coaching['treatment_PS'] = data_coaching[[\n",
    "        'Psychosocial support and/or counselling']].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels_recomm = [\n",
    "    'Dietary modification',\n",
    "    'Exercise modification',\n",
    "    'Behavioural modification',\n",
    "    'Medication adherence',\n",
    "    'Medication adjustment',\n",
    "    'Glucose monitoring',\n",
    "    'Psychosocial support and/or counselling',\n",
    "    'Case-management/monitoring',\n",
    "    'System navigation'\n",
    "    ]\n",
    "\n",
    "levels_trt = [\n",
    "    'treatment_BC+DE', \n",
    "    'treatment_CM', \n",
    "    'treatment_PS'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map date of coaching with stages\n",
    "## Stage 1: baseline to 6m follow-up visit\n",
    "## Stage 2: 6m follow-up visit to 12m follow-up visit\n",
    "for id in set(data['id']):\n",
    "\n",
    "    # extract visit dates for baseline, 6m and 12m visits\n",
    "    date_bl = data[(data['id']==id)&(data['VISIT']==0)]['VISIT DATE'].values[0]\n",
    "    date_6m = data[(data['id']==id)&(data['VISIT']==1)]['VISIT DATE'].values[0]\n",
    "    date_12m = data[(data['id']==id)&(data['VISIT']==2)]['VISIT DATE'].values[0]\n",
    "    \n",
    "    # Stage 1: baseline to 6m follow-up visit\n",
    "    # Stage 2: 6m follow-up visit to 12m follow-up visit\n",
    "    data_coaching.loc[(data_coaching['id']==id)&(data_coaching['date of coaching']>=date_bl)&(data_coaching['date of coaching']<date_6m), 'interval'] = 1\n",
    "    data_coaching.loc[(data_coaching['id']==id)&(data_coaching['date of coaching']>=date_6m)&(data_coaching['date of coaching']<=date_12m), 'interval'] = 2\n",
    "    data_coaching['interval'].fillna('out of bound', inplace = True)\n",
    "\n",
    "print(data_coaching[['interval']].value_counts())\n",
    "\n",
    "# Remove coaching data if the date of coaching is out of bound (i.e., not in stage 1 or stage 2)\n",
    "data_coaching = data_coaching[data_coaching['interval']!='out of bound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering on coaching data\n",
    "def coaching_fe(data, levels_recomm, levels_trt, interval):\n",
    "\n",
    "    # Overall intensity: total # of coaching recommendation\n",
    "    recomm_count = pd.DataFrame(data[levels_recomm+['id']].groupby('id').agg('sum')[levels_recomm].sum(axis=1))\n",
    "    recomm_count.rename(columns = {recomm_count.columns[0]: 'recomm_count'}, inplace = True)\n",
    "    \n",
    "    # Relative intensity: proportion of each coaching recommendation\n",
    "    data[levels_recomm] = data[levels_recomm].fillna(0)\n",
    "    recomm = data[levels_recomm+['id']].groupby('id').agg('sum')\n",
    "    recomm = recomm.merge(recomm_count, on = 'id')\n",
    "    for col in levels_recomm:\n",
    "        recomm[col] = recomm[col]/recomm['recomm_count']\n",
    "        \n",
    "    # Overall intensity: total # of treatment\n",
    "    trt_count = pd.DataFrame(data[levels_trt+['id']].groupby('id').agg('sum')[levels_trt].sum(axis=1))\n",
    "    trt_count.rename(columns = {trt_count.columns[0]: 'trt_count'}, inplace = True)\n",
    "\n",
    "    # Relative intensity: proportion of each treatment\n",
    "    data[levels_trt] = data[levels_trt].fillna(0)\n",
    "    trt = data[levels_trt+['id']].groupby('id').agg('sum')\n",
    "    trt = trt.merge(trt_count, on = 'id')\n",
    "    for col in levels_trt:\n",
    "        trt[col] = trt[col]/trt['trt_count']\n",
    "\n",
    "    # Join recommendation and treatment\n",
    "    coaching = reduce(lambda x, y: x.merge(y, on='id'), [recomm.fillna(0), trt.fillna(0)])\n",
    "    coaching['interval'] = interval\n",
    "    \n",
    "    return coaching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering on coaching data\n",
    "data_coaching_s1 = coaching_fe(data_coaching[data_coaching['interval']==1], levels_recomm, levels_trt, interval=1)\n",
    "data_coaching_s2 = coaching_fe(data_coaching[data_coaching['interval']==2], levels_recomm, levels_trt, interval=2)\n",
    "coaching = pd.concat([data_coaching_s1, data_coaching_s2], axis = 0)\n",
    "\n",
    "# Join patient characteristics (state) with coaching data (action)\n",
    "data = data.merge(coaching, left_on = ['id', 'VISIT'], right_on = ['id', 'interval'], how = 'left')\n",
    "\n",
    "# Fill missing values with 0\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the action space\n",
    "\n",
    "## Intensity:\n",
    "avg_intensity = np.median(data[data['VISIT'].isin([1, 2])]['trt_count']); print(avg_intensity)\n",
    "data['intensity'] = np.where(data['trt_count'] > avg_intensity, 'high', 'low')\n",
    "\n",
    "# Focus: coaching delivered in a stage can be classified as focused on one of the three treatments if a patient have at least twice as many treatments in one category compared to the others – otherwise they were classified as general coaching.\n",
    "data['focus'] = np.where(data['treatment_BC+DE']/data['treatment_CM']>2, 'treatment_BC+DE',\n",
    "                         np.where(data['treatment_CM']/data['treatment_BC+DE']>2, 'treatment_CM', 'treatment_mix'))\n",
    "\n",
    "# Define an action using two dimensions: intensity and focus\n",
    "data['treatment'] = data['intensity']+'_'+data['focus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the action variable\n",
    "data = data.rename(columns = {'treatment':'action'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the composite clinical outcome variable as 0.5*relative reduction in HbA1c + 0.5**relative improvement in EQ5D\n",
    "HbA1c_weight = 0.5\n",
    "data['outcome'] = HbA1c_weight * data['HbA1c_rel_scaled'] + (1-HbA1c_weight) * data['EQ5D_rel_scaled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the action space\n",
    "action_dict = {\n",
    "    'low_treatment_BC+DE': 0, 'low_treatment_CM': 1, 'low_treatment_mix': 2,\n",
    "    'high_treatment_BC+DE': 3, 'high_treatment_CM': 4, 'high_treatment_mix': 5\n",
    "}\n",
    "\n",
    "action_dict_inverse = {\n",
    "    0: 'treatment_BC+DE', 1: 'treatment_CM', 2: 'treatment_mix',\n",
    "    3: 'high intensity treatment_BC+DE', 4: 'high intensity treatment_CM', 5: 'high intensity treatment_mix'\n",
    "}\n",
    "\n",
    "data['action'] = data['action'].replace(action_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order-encoding the categorical variables\n",
    "enc = preprocessing.OrdinalEncoder()\n",
    "data[covariate_cat+['action']] = enc.fit_transform(data[covariate_cat+['action']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation for the dynamic treatment regime model\n",
    "predictors = covariate_num+covariate_cat\n",
    "\n",
    "# State\n",
    "X = data[data['VISIT'].isin([0, 1])][['id', 'VISIT'] + predictors]\n",
    "X1 = X[X['VISIT']==0].drop(columns = ['VISIT'])\n",
    "X2 = X[X['VISIT']==1].drop(columns = ['VISIT'])\n",
    "\n",
    "# Reward\n",
    "y1 = data[data['VISIT']==1][['outcome', 'id']]\n",
    "y2 = data[data['VISIT']==2][['outcome', 'id']]\n",
    "\n",
    "# Action\n",
    "A1 = data[data['VISIT']==1][['action', 'id']]\n",
    "A2 = data[data['VISIT']==2][['action', 'id']]\n",
    "\n",
    "df1 = reduce(lambda x,y: pd.merge(x, y, on = 'id'), [X1, A1, y1])\n",
    "df2 = reduce(lambda x,y: pd.merge(x, y, on = 'id'), [X2, A2, y2])\n",
    "\n",
    "df1.columns = df1.columns+'_1'\n",
    "df2.columns = df2.columns+'_2'\n",
    "\n",
    "df = pd.merge(df1, df2, left_on = 'id_1', right_on = 'id_2').drop(columns = ['id_1', 'id_2'])\n",
    "cols = df.columns.to_list()\n",
    "\n",
    "cat_idx_stage1 = [df.columns.get_loc(c) for c in [col+'_1' for col in covariate_cat+['action']] if c in df]\n",
    "cat_idx_stage2 = [df.columns.get_loc(c) for c in [col+'_1' for col in covariate_cat+['action']]+[col+'_2' for col in covariate_cat+['action']] if c in df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model development\n",
    "\n",
    "# specify hyper-parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5], \n",
    "    'max_iter': [50, 100, 200, 1000], \n",
    "    'max_depth': [5, 10, None],\n",
    "    'l2_regularization': [0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "params = [dict(zip(param_grid.keys(), value)) for value in product(*param_grid.values())]\n",
    "\n",
    "# For loop for hyperpamameter tuning\n",
    "outcomes_stage2 = []\n",
    "\n",
    "for param in params:\n",
    "    \n",
    "    param1 = param.copy(); param1.update({'categorical_features': cat_idx_stage1})\n",
    "    param2 = param.copy(); param2.update({'categorical_features': cat_idx_stage2})\n",
    "\n",
    "    model_info = [\n",
    "        {\n",
    "            \"model\": HistGradientBoostingRegressor(**param1),\n",
    "            \"action_dict\": {\"action_1\": [0, 1, 2, 3, 4, 5]},\n",
    "            \"feature\": df1.drop(columns = [\"id_1\", \"outcome_1\"]).columns.to_list(),\n",
    "            \"outcome\": \"outcome_1\",\n",
    "            \"importance\": False\n",
    "        },\n",
    "        {\n",
    "            \"model\": HistGradientBoostingRegressor(**param2),\n",
    "            \"action_dict\": {\"action_2\": [0, 1, 2, 3, 4, 5]},\n",
    "            \"feature\": df.drop(columns = [\"outcome_2\"]).columns.to_list(),\n",
    "            \"outcome\": \"outcome_2\",\n",
    "            \"importance\": False\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Fit model\n",
    "    dtr_model = IqLearnReg(n_stages = 2, model_info = model_info)\n",
    "    dtr_model.fit(df)\n",
    "    \n",
    "    # Compute the predicted end-of-stage 2 outcome\n",
    "    res_stage2 =  dtr_model.predict(df, 1).rename(columns = {'val': 'val2'})\n",
    "    outcomes_stage2.append(res_stage2['val2'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the hyperparameters associated the best predicted end-of-stage 2 outcome\n",
    "param_selected = params[np.argmax(outcomes_stage2)]\n",
    "\n",
    "param1 = param_selected.copy(); param1.update({'categorical_features': cat_idx_stage1})\n",
    "param2 = param_selected.copy(); param2.update({'categorical_features': cat_idx_stage2})\n",
    "\n",
    "model_info = [\n",
    "    {\n",
    "        \"model\": HistGradientBoostingRegressor(**param1),\n",
    "        \"action_dict\": {\"action_1\": [0, 1, 2, 3, 4, 5]},\n",
    "        \"feature\": df1.drop(columns = [\"id_1\", \"outcome_1\"]).columns.to_list(),\n",
    "        \"outcome\": \"outcome_1\",\n",
    "        \"importance\": False\n",
    "    },\n",
    "    {\n",
    "        \"model\": HistGradientBoostingRegressor(**param2),\n",
    "        \"action_dict\": {\"action_2\": [0, 1, 2, 3, 4, 5]},\n",
    "        \"feature\": df.drop(columns = [\"outcome_2\"]).columns.to_list(),\n",
    "        \"outcome\": \"outcome_2\",\n",
    "        \"importance\": False\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the results\n",
    "\n",
    "## Stage 1\n",
    "res_stage1 = dtr_model.predict(df, 0).rename(columns = {'val': 'val1'})\n",
    "## Stage 2\n",
    "res_stage2 = dtr_model.predict(df, 1).rename(columns = {'val': 'val2'})\n",
    "## Combine the results from stages 1 and 2\n",
    "res = res_stage1.merge(res_stage2, how = 'inner', left_index = True, right_index = True)\n",
    "\n",
    "# Calcualte the model's objective function value\n",
    "res['objective_function'] = res['val1']\n",
    "print('Model estimated (discounted) sum of reward:', res['objective_function'].mean(), sep = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the observed results\n",
    "\n",
    "## Stage 1\n",
    "y1 = y1.rename(columns = {'outcome': 'outcome1'})\n",
    "## Stage 2\n",
    "y2 = y2.rename(columns = {'outcome': 'outcome2'})\n",
    "## Combine the observed results from stages 1 and 2\n",
    "res_obs = y1.merge(y2, how = 'inner', left_on = 'id', right_on = 'id')\n",
    "\n",
    "# Calcualte the observed objective function value\n",
    "res_obs['objective_function'] = res_obs['outcome1'] + res_obs['outcome2']\n",
    "print('Observed (discounted) sum of reward:', res_obs['objective_function'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for statistical significance (paired t test)\n",
    "print(ttest_rel(res['objective_function'], res_obs['objective_function']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
